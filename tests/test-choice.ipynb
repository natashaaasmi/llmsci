{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import load_tools\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "llm=OpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test- generate list of colors\n",
    "llm = OpenAI(temperature=0.5)\n",
    "template = \"\"\"\n",
    "Generate a numbered list of five things of the following type: {type}\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"type\"], template=template)\n",
    "list_chain = LLMChain(\n",
    "    llm=llm, prompt=prompt_template, output_key=\"list\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose a thing from the list\n",
    "llm=OpenAI(temperature=0.5)\n",
    "template = \"\"\"\n",
    "Choose one thing from the list that has the most in common with a fire hydrant: {list}\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"list\"], template=template)\n",
    "choice_chain = LLMChain(\n",
    "    llm=llm, prompt=prompt_template, output_key=\"choice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate that thing into Klingon\n",
    "llm=OpenAI(temperature=0.5)\n",
    "template = \"\"\"\n",
    "Translate the following thing into Klingon: {choice}\n",
    "\"\"\"\n",
    "prompt_template=PromptTemplate(\n",
    "    input_variables=[\"choice\"], template=template\n",
    ")\n",
    "translate_chain=LLMChain(\n",
    "    llm=llm, prompt=prompt_template,output_key=\"translation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "choosing_chain =SequentialChain(\n",
    "    chains=[list_chain, choice_chain, translate_chain],\n",
    "    input_variables=[\"type\"],\n",
    "    output_variables=[\"list\",\"choice\",\"translation\"],\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\u001b[1mChain 0\u001b[0m:\n",
      "{'list': '\\n1. Red\\n2. Blue\\n3. Green\\n4. Yellow\\n5. Orange'}\n",
      "\n",
      "\u001b[1mChain 1\u001b[0m:\n",
      "{'choice': '\\nAnswer: 1. Red'}\n",
      "\n",
      "\u001b[1mChain 2\u001b[0m:\n",
      "{'translation': 'jIH'}\n",
      "\n",
      "\n",
      "\u001b[1m> Finished SequentialChain chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "type=input(\"Enter a type\")\n",
    "output = choosing_chain({\"type\": type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing a multi-input llmchain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "llm = OpenAI()\n",
    "template = \"\"\" \n",
    "Write a {type} based on the following prompt: {prompt}\n",
    "\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"type\", \"prompt\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    output_key=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'story',\n",
       " 'prompt': 'Once upon a time',\n",
       " 'text': \"Once upon a time, there was a young girl named Sarah who lived in a small village. She was always the adventurous type, and often explored the nearby forests, despite her parents' warnings.\\n\\nOne day, Sarah stumbled upon a mysterious cave in the woods. Despite her fear, she decided to explore it. Inside the cave, she found a magical amulet that glowed a bright blue light. She quickly picked it up and put it around her neck.\\n\\nThe amulet granted Sarah magical powers, and so she began to use them to help her village. She used her newfound magic to protect the villagers from danger and to bring prosperity to the land.\\n\\nThe villagers were so thankful for Sarah's help that they rewarded her with riches and fame. Sarah was now a hero, and the amulet was a symbol of her courage and strength.\\n\\nSarah continued to use her powers to help her village for many years to come. She was a beloved leader and an example of what bravery and kindness can do.\\n\\nSarah's story spread far and wide, and the magical amulet was a reminder to all that with courage and kindness, anything was possible.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain({\"type\": \"story\", \"prompt\": \"Once upon a time\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
